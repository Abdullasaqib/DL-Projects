{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iYWS_l8coJGx"
   },
   "outputs": [],
   "source": [
    "## import tensorflow\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qdTAg7_xoNbR"
   },
   "outputs": [],
   "source": [
    "# Importing the IMDb dataset from Keras. This dataset contains 25,000 highly polar movie reviews.\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WbF-DdLWoRbZ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# Importing the Tokenizer class for text preprocessing.\n",
    "# Tokenizer is used to vectorize a text corpus by turning each text into either a sequence of integers\n",
    "# (each integer being the index of a token in a dictionary) or into a matrix where each row is the vector representation of a text.\n",
    "# It works by first building an index of all the unique tokens (words) in the text, then encoding each word with a unique integer.\n",
    "# It allows for efficient handling of text data when preparing it for input into a neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "L9LwcKX4oUX7"
   },
   "outputs": [],
   "source": [
    "# Load the IMDB dataset with a specified vocabulary size\n",
    "# imdb.load_data() loads the IMDB movie review dataset,\n",
    "#which is a dataset of 25,000 movie reviews from IMDB, labeled by sentiment (positive/negative).\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=20000)\n",
    "# The num_words parameter specifies the maximum number of words to include in the dataset.\n",
    "# Only the top 20,000 most frequently occurring words in the dataset will be considered.\n",
    "# The function returns two tuples:\n",
    "# (X_train, y_train): Training data and labels.\n",
    "# (X_test, y_test): Testing data and labels.\n",
    "# X_train and X_test are lists of sequences, where each sequence is a list of integers representing the words in a review.\n",
    "# y_train and y_test are lists of integers (0 or 1), where 0 indicates a negative review and 1 indicates a positive review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1JoOshTqosgw"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "# Importing sequence for padding sequences to the same length.\n",
    "# Padding ensures that all input sequences are of the same length, which is required by the neural network.\n",
    "# Sequences shorter than the specified length are padded with zeros (by default) at the beginning.\n",
    "# Sequences longer than the specified length are truncated so that all sequences have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bWpGOGa2o4mH"
   },
   "outputs": [],
   "source": [
    "# Pad sequences to a maximum length of 200\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=200)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=200)\n",
    "# sequence.pad_sequences() is used to ensure that all sequences (lists of integers) in the dataset have the same length.\n",
    "# This function pads shorter sequences with zeros at the beginning by default, so they all have the same length, specified by the maxlen parameter.\n",
    "# In this case, maxlen=200 means that each sequence will be either truncated to 200 words (if longer) or padded with zeros to 200 words (if shorter).\n",
    "# Padding sequences to the same length is essential because neural networks expect input data to have a consistent shape.\n",
    "# For instance, an RNN (Recurrent Neural Network) requires all input sequences to have the same length to be processed in batches.\n",
    "# By setting maxlen=200, we ensure that all movie reviews in X_train and X_test are of length 200, making them suitable for input into the RNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "G7tZXpyFo70C"
   },
   "outputs": [],
   "source": [
    "# Importing the Sequential model class for building a linear stack of layers.\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "## importing the necessary layers\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "# Add an Embedding layer to the model\n",
    "model.add(Embedding(input_dim=20000, output_dim=32)) # Embedding layer to convert word indices to dense vectors of fixed size (32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-BrfubdYpKPo"
   },
   "outputs": [],
   "source": [
    "# Add a SimpleRNN layer to the model\n",
    "model.add(SimpleRNN(32)) # SimpleRNN layer with 32 units. This layer processes the sequence of word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_jDUD9sbpM9U"
   },
   "outputs": [],
   "source": [
    "# Add a Dense layer with 100 neurons and ReLU activation\n",
    "model.add(Dense(units = 100, activation =\"relu\"))\n",
    "# Add an output Dense layer with 1 neuron and sigmoid activation for binary classification\n",
    "model.add(Dense(units = 1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XzneghkUpQ4x"
   },
   "outputs": [],
   "source": [
    "# Compile the model with Adam optimizer and binary cross-entropy loss function\n",
    "model.compile(optimizer = \"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRfMa4-cpdBS",
    "outputId": "0c2f81a6-1ed3-4bb3-ff67-24bdc935dd7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 30ms/step - accuracy: 0.5681 - loss: 0.6493\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - accuracy: 0.8600 - loss: 0.3335\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.9340 - loss: 0.1748\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 31ms/step - accuracy: 0.9323 - loss: 0.1765\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.9842 - loss: 0.0477\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.9917 - loss: 0.0289\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - accuracy: 0.9710 - loss: 0.0819\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - accuracy: 0.9895 - loss: 0.0335\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - accuracy: 0.9945 - loss: 0.0158\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.9974 - loss: 0.0084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2649731ee70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on the training data for 5 epochs\n",
    "model.fit(X_train,y_train,epochs= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nQ5N0QyGpgBM"
   },
   "outputs": [],
   "source": [
    "# Custom sentence for sentiment analysis\n",
    "sentences = \"worst movie i have ever seen in my whole life\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1zYeEtUppnjW"
   },
   "outputs": [],
   "source": [
    "# Preprocess the sentence\n",
    "sentence = sentences.lower().split() # Converts the sentence to lowercase and splits it into a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjnw7tL4pwLO",
    "outputId": "0e25052a-d59c-4d67-9d72-8b8978be56ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worst', 'movie', 'i', 'have', 'ever', 'seen', 'in', 'my', 'whole', 'life']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the preprocessed sentence\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "KkO9YjPGpwsU"
   },
   "outputs": [],
   "source": [
    "# Get the word index from the IMDb dataset\n",
    "word_index = imdb.get_word_index() # Returns a dictionary mapping words to their integer index in the IMDb dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zioci_xnpzcx"
   },
   "outputs": [],
   "source": [
    "# Convert the sentence to a list of tokens (word indices)\n",
    "tokens = [word_index.get(word, 0) for word in sentence]\n",
    "# This line creates a list of integers (tokens) by mapping each word in the sentence to its corresponding index using the word_index dictionary.\n",
    "# If a word is not found in the word_index, it returns 0 by default (due to the get method's default value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lSzCFIdPp8-z",
    "outputId": "dd10187b-f9ad-4aa1-920b-4170db0aea11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[246, 17, 10, 25, 123, 107, 8, 58, 223, 110]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the tokenized sentence\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Smzd23U3qCGW"
   },
   "outputs": [],
   "source": [
    "# Pad the tokenized sentence to a maximum length of 200\n",
    "tokens = sequence.pad_sequences([tokens],maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBhTTjPIqEc-",
    "outputId": "8ec6add4-143e-4ab7-96e4-1c5f96866645"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0, 246,  17,  10,  25, 123,\n",
       "        107,   8,  58, 223, 110]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the padded tokens\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2G67NmXqG80",
    "outputId": "cdbd2585-16fd-419a-d73e-58fbfc1a2f5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict the sentiment of the padded sentence\n",
    "prediction = model.predict(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0pCNEhDPqJ2g",
    "outputId": "836af58c-00e3-4bf0-ab95-2d10cec510ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00018835]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the prediction score\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A66UP_uYqPcV",
    "outputId": "8706547c-f01c-48fb-876c-c8440c07ef31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "# Interpret the prediction\n",
    "if prediction[0][0]>0.5:\n",
    "  print(\"positive\")\n",
    "else:\n",
    "  print(\"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGqxPDEnqRUI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

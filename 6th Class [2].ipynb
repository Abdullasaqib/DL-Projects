{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4c13d92-1bfa-4f48-a0e0-51acd441e1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence, text\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, SimpleRNN\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cd63a0d-14e1-4a36-b6ae-bc7953fcef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDb dataset\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=50000)\n",
    "# Pad sequences to ensure uniform length\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=100)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=100)\n",
    "# Initialize the model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8ebea0b-a0fe-4b6e-8d8a-fad1582db05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 40ms/step - accuracy: 0.5572 - loss: 0.6741\n",
      "Epoch 2/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.7576 - loss: 0.5008\n",
      "Epoch 3/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.8418 - loss: 0.3729\n",
      "Epoch 4/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.8752 - loss: 0.3065\n",
      "Epoch 5/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9012 - loss: 0.2576\n",
      "Epoch 6/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9150 - loss: 0.2282\n",
      "Epoch 7/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9221 - loss: 0.2097\n",
      "Epoch 8/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9331 - loss: 0.1833\n",
      "Epoch 9/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9326 - loss: 0.1873\n",
      "Epoch 10/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9376 - loss: 0.1775\n",
      "Epoch 11/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9500 - loss: 0.1435\n",
      "Epoch 12/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9594 - loss: 0.1246\n",
      "Epoch 13/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9583 - loss: 0.1238\n",
      "Epoch 14/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9539 - loss: 0.1352\n",
      "Epoch 15/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9649 - loss: 0.1079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fe23d44e30>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an Embedding layer\n",
    "model.add(Embedding(50000, 128))\n",
    "# Add a SimpleRNN layer\n",
    "model.add(SimpleRNN(128,activation='sigmoid', dropout=0.2, recurrent_dropout=0.2))\n",
    "# Add a Dense layer with sigmoid activation\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc19e0b3-25db-4149-b80a-20d571dcffe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7417 - loss: 0.8320\n",
      "Test loss: 0.8185733556747437,\n",
      " Test accuracy: 0.7468400001525879\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(f\"Test loss: {score},\\n Test accuracy: {acc}\")\n",
    "# Tokenizer to process custom reviews\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(imdb.get_word_index().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d38be755-8a38-402d-97e5-34cd7269676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess custom review\n",
    "from keras.preprocessing import sequence  # Ensure the sequence module is imported\n",
    "# Preprocess custom review\n",
    "def preprocess_review(review, maxlen=100):\n",
    "    sequence_list = tokenizer.texts_to_sequences([review])\n",
    "    padded_sequence = sequence.pad_sequences(sequence_list, maxlen=maxlen)  # Correct method call here\n",
    "    return padded_sequence\n",
    "# Predict sentiment for custom reviews\n",
    "def predict_sentiment(review):\n",
    "    preprocessed_review = preprocess_review(review)\n",
    "    prediction = model.predict(preprocessed_review)\n",
    "    sentiment = \"Positive\" if prediction >= 0.5 else \"Negative\"\n",
    "    return sentiment, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5ba91f0-881c-403e-be7d-d04b31b803d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Review: bad\n",
      "Sentiment: Positive (Probability: 0.99)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example custom review\n",
    "custom_review = \"bad\"\n",
    "\n",
    "# Predict sentiment for the custom review\n",
    "sentiment, probability = predict_sentiment(custom_review)\n",
    "print(f\"Review: {custom_review}\\nSentiment: {sentiment} (Probability: {probability[0][0]:.2f})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe240c3-3595-40c7-bcfa-a355fab00ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
